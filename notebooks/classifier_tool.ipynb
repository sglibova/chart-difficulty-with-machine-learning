{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, the intent is to classify a song using its data as \"stamina\" or \"tech\" to add a feature to the app which removes user input and instead detects which rating model should be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, precision_score, recall_score, accuracy_score, f1_score,\\\n",
    "                            roc_curve, auc, classification_report, log_loss, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from statsmodels.api import qqplot\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance, plot_tree, DMatrix\n",
    "import shap\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##display all dataframe columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "stam = pd.read_csv(\"../data/stam.csv\")\n",
    "tech = pd.read_csv(\"../data/not_stam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data_cleaning import data_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Tech DataFrame with 4808 rows.\n",
      "\n",
      "Removing outliers and filling NaN values...\n",
      "\n",
      "The songs in this Tech dataset are up to 164.002 seconds (2.733 minutes) long.\n",
      "The songs in this Tech dataset have up to 826 steps.\n",
      "The songs in this Tech dataset have a max  bpm weighted average up to 175 bpm.\n",
      "The songs in this Tech dataset have up to 21 bpm changes.\n",
      "The songs in this Tech dataset have up to 6.387 NPS.\n",
      "\n",
      "Returning cleaned Tech DataFrame with 3209 rows and 31 columns.\n"
     ]
    }
   ],
   "source": [
    "cleaned_tech = data_cleaner(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Stamina DataFrame with 2926 rows.\n",
      "\n",
      "Removing outliers and filling NaN values...\n",
      "\n",
      "The songs in this Stamina dataset are up to 1695.086 seconds (28.251 minutes) long.\n",
      "The songs in this Stamina dataset have up to 16804steps.\n",
      "The songs in this Stamina dataset have a max  bpm weighted average up to 216 bpm.\n",
      "The songs in this Stamina dataset have up to 4 bpm changes.\n",
      "The songs in this Stamina dataset have up to 10.866 NPS.\n",
      "\n",
      "Returning cleaned Stamina DataFrame with 2255 rows and 40 columns.\n"
     ]
    }
   ],
   "source": [
    "cleaned_stam = data_cleaner(stam, is_stamina = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tech['target'] = 0\n",
    "cleaned_stam['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pd.concat([cleaned_tech, cleaned_stam], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to some columns being removed from the tech dataset for being irrelevant, I will fill the NaN values with 0\n",
    "\n",
    "all_songs = all_songs.fillna(0)\n",
    "\n",
    "#shuffling the dataframe to mix the target values\n",
    "\n",
    "all_songs = all_songs.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_songs.drop(columns=['target', 'title', 'artist', 'difficulty'], axis=1)\n",
    "target = all_songs.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5444    0\n",
       "4907    0\n",
       "2320    1\n",
       "2596    0\n",
       "3481    1\n",
       "       ..\n",
       "3236    1\n",
       "4100    0\n",
       "3350    0\n",
       "243     1\n",
       "4681    0\n",
       "Name: target, Length: 1025, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pipe = Pipeline([('scaler', StandardScaler()), ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipe.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = classifier_pipe.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_preds != y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = classifier_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_predictions != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
